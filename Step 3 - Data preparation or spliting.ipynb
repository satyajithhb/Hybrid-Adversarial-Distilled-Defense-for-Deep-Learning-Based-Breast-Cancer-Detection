{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPieM5HyxY8L7YTcvZyGXDF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qsaX1LGugrd7"},"outputs":[],"source":["# Step 1: Import Libraries and Initialize Constants\n","import os\n","import shutil\n","import glob\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"7dlMXypjg0Re","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740578872375,"user_tz":-360,"elapsed":33111,"user":{"displayName":"Thesis Group","userId":"00342594847503543905"}},"outputId":"2854e514-b38c-47c5-b575-38cbdaf7f1de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Constants and Configurations\n","BASE_DIR = \"/content/drive/MyDrive/V1.0 for BreakHis/BreakHis_dataset_augmented\"\n","SAVE_BASE_DIR = \"/content/drive/MyDrive/BreakHis_dataset_split\"\n","TEST_RATIO = 0.3\n","IMG_EXT = \"*.png\""],"metadata":{"id":"MJu7xAJ-g1vN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 2: Utility Functions\n","def ensure_dir_exists(directory):\n","    os.makedirs(directory, exist_ok=True)\n","\n","def split_dataset(image_paths, test_ratio=TEST_RATIO, validation_ratio=0.5):\n","    # Create labels based on the presence of 'benign' in the file path (otherwise 'malignant')\n","    labels = ['benign' if 'benign' in path.lower() else 'malignant' for path in image_paths]\n","    train_paths, temp_paths = train_test_split(\n","        image_paths, test_size=test_ratio, stratify=labels, random_state=42\n","    )\n","    # For temp_paths, use the immediate folder name (assumed to be the class) for stratification\n","    val_paths, test_paths = train_test_split(\n","        temp_paths, test_size=validation_ratio,\n","        stratify=[os.path.basename(os.path.dirname(p)) for p in temp_paths],\n","        random_state=42\n","    )\n","    return train_paths, val_paths, test_paths\n","\n","def organize_dataset(paths, target_dir):\n","    \"\"\"Organize dataset into labeled subfolders by copying images.\"\"\"\n","    for path in tqdm(paths, desc=f\"Saving to {os.path.basename(target_dir)}\"):\n","        try:\n","            # Determine class label based on file path\n","            class_label = 'benign' if 'benign' in path.lower() else 'malignant'\n","            class_dir = os.path.join(target_dir, class_label)\n","            ensure_dir_exists(class_dir)\n","            shutil.copy(path, os.path.join(class_dir, os.path.basename(path)))\n","        except Exception as e:\n","            print(f\"Error copying {path} to {class_dir}: {e}\")\n","\n","def prepare_dataset(base_dir, save_base_dir):\n","    \"\"\"Prepare dataset directories and save images into train, validation, and test splits.\"\"\"\n","    print(\"Preparing dataset...\")\n","    # Recursively find all jpg images\n","    image_paths = glob.glob(os.path.join(base_dir, '**', IMG_EXT), recursive=True)\n","    print(f\"Total images found: {len(image_paths)}\")\n","\n","    # Split dataset\n","    train_paths, val_paths, test_paths = split_dataset(image_paths)\n","\n","    # Define directories for each split\n","    splits = {\n","        \"train\": os.path.join(save_base_dir, 'train'),\n","        \"validation\": os.path.join(save_base_dir, 'validation'),\n","        \"test\": os.path.join(save_base_dir, 'test'),\n","    }\n","    for directory in splits.values():\n","        ensure_dir_exists(directory)\n","\n","    # Organize images into respective folders\n","    organize_dataset(train_paths, splits[\"train\"])\n","    organize_dataset(val_paths, splits[\"validation\"])\n","    organize_dataset(test_paths, splits[\"test\"])\n","\n","    return splits"],"metadata":{"id":"Rk3EeD-jg3Rd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 3: Prepare Dataset\n","print(\"Starting dataset preparation...\")\n","splits = prepare_dataset(BASE_DIR, SAVE_BASE_DIR)\n","print(f\"Train directory: {splits['train']}\")\n","print(f\"Validation directory: {splits['validation']}\")\n","print(f\"Test directory: {splits['test']}\")"],"metadata":{"id":"rnjiKAvJg7mR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740580839040,"user_tz":-360,"elapsed":1966665,"user":{"displayName":"Thesis Group","userId":"00342594847503543905"}},"outputId":"a8fc7e22-c61a-44a5-b3bf-2b5e9aceb07d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting dataset preparation...\n","Preparing dataset...\n","Total images found: 10858\n"]},{"output_type":"stream","name":"stderr","text":["Saving to train: 100%|██████████| 7600/7600 [24:27<00:00,  5.18it/s]\n","Saving to validation: 100%|██████████| 1629/1629 [03:56<00:00,  6.90it/s]\n","Saving to test: 100%|██████████| 1629/1629 [04:04<00:00,  6.67it/s]"]},{"output_type":"stream","name":"stdout","text":["Train directory: /content/drive/MyDrive/BreakHis_dataset_split/train\n","Validation directory: /content/drive/MyDrive/BreakHis_dataset_split/validation\n","Test directory: /content/drive/MyDrive/BreakHis_dataset_split/test\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}